{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTJbwQY4Af5wH+6rH7rQEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jivemachine/DCGAN/blob/main/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfFjG7q_-uw5"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTId-2u-sBH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rYFwRfOAoQK",
        "outputId": "542d3897-eebe-4a0f-ece3-20b8bf8d090f"
      },
      "source": [
        "# pulling fashion mnist dataset from keras' dataset library\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255 # normalizing train data\n",
        "X_test = X_test.astype(np.float32) / 255 # normalizing test data\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sWyXWQ8AyAv"
      },
      "source": [
        "coding_size = 100\n",
        "# building the generator\n",
        "generator = keras.models.Sequential([\n",
        "  keras.layers.Dense(7 * 7 * 128, input_shape=[coding_size]),\n",
        "  keras.layers.Reshape([7, 7, 128]),\n",
        "  keras.layers.BatchNormalization(),\n",
        "  keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding='same', activation='selu'),\n",
        "  keras.layers.BatchNormalization(),\n",
        "  keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding='same', activation='tanh')              \n",
        "])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zX6s0QeEegi"
      },
      "source": [
        "# building discriminator\n",
        "discriminator = keras.models.Sequential([\n",
        "  keras.layers.Conv2D(64, kernel_size=5, strides=2, padding='same', activation=keras.layers.LeakyReLU(0.2), input_shape=[28, 28, 1]),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Conv2D(128, kernel_size=5, strides=2, padding='same', activation=keras.layers.LeakyReLU(0.2)),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')                                                                                    \n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OPE36oWFnnQ"
      },
      "source": [
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh0We-ODGlw6"
      },
      "source": [
        "# compiling the discriminator & the gan\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=\"rmsprop\")\n",
        "discriminator.trainable=False\n",
        "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9IVuxzEFvPp"
      },
      "source": [
        "# we need to reshape the training data to the same range as the generator\n",
        "X_train = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape & rescale"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5u-20o9HEbC"
      },
      "source": [
        "# since the training loop is unusual we need to write a custom training loop for the model\n",
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKsQH3mVIAwL"
      },
      "source": [
        "# code so we can see the generated images from the gan\n",
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC6Dj-J-IVmk"
      },
      "source": [
        "# training loop\n",
        "def train_gan(gan, dataset, batch_size, size, n_epochs=50):\n",
        "  generator, discriminator = gan.layers\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "    for X_batch in dataset:\n",
        "      # phase 1 - training the discriminator\n",
        "      noise = tf.random.normal(shape=[batch_size, size])\n",
        "      generated_images = generator(noise)\n",
        "      X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "      y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "      discriminator.trainable = False\n",
        "      discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "      # phase 2 - training the generator\n",
        "      noise = tf.random.normal(shape=[batch_size, size])\n",
        "      y2 = tf.constant([[1.]] * batch_size)\n",
        "      discriminator.trainable = False\n",
        "      gan.train_on_batch(noise, y2)\n",
        "    plot_multiple_images(generated_images, 8)\n",
        "    plt.show()                     "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj9Jbz2xItze"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}